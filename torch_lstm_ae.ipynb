{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection\n",
    "\n",
    "https://joungheekim.github.io/2020/11/14/code-review/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import easydict\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from celluloid import Camera\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 불러오기\n",
    "df = pd.read_csv('sensor.csv', index_col=0)\n",
    "## 데이터 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 불러올 때 index로 불러오기\n",
    "def make_data_idx(dates, window_size=1):\n",
    "    input_idx = []\n",
    "    for idx in range(window_size-1, len(dates)):\n",
    "        cur_date = dates[idx].to_pydatetime()\n",
    "        in_date = dates[idx - (window_size-1)].to_pydatetime()\n",
    "        \n",
    "        _in_period = (cur_date - in_date).days * 24 * 60 + (cur_date - in_date).seconds / 60\n",
    "        \n",
    "        ## 각 index가 1분 간격으로 떨어져 있는지를 확인합니다.\n",
    "        if _in_period == (window_size-1):\n",
    "            input_idx.append(list(range(idx - window_size+1, idx+1)))\n",
    "    return input_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset을 상속받아 데이터를 구성\n",
    "class TagDataset(Dataset):\n",
    "    def __init__(self, input_size, df, mean_df=None, std_df = None, window_size=1):\n",
    "        \n",
    "        ## 변수 갯수\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        ## 복원할 sequence 길이\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        ## Summary용 데이터 Deep copy\n",
    "        original_df = df.copy()\n",
    "        \n",
    "        ## 정규화\n",
    "        if mean_df is not None and std_df is not None:\n",
    "            sensor_columns = [item for item in df.columns if 'sensor_' in item]\n",
    "            df[sensor_columns] = (df[sensor_columns]-mean_df)/std_df\n",
    "        \n",
    "        ## 연속한 index를 기준으로 학습에 사용합니다.\n",
    "        dates = list(df['date'])\n",
    "        self.input_ids = make_data_idx(dates, window_size=window_size)\n",
    "        \n",
    "        ## sensor 데이터만 사용하여 reconstruct에 활용\n",
    "        self.selected_column = [item for item in df.columns if 'sensor_' in item][:input_size]\n",
    "        self.var_data = torch.tensor(df[self.selected_column].values, dtype=torch.float)\n",
    "        \n",
    "        ## Summary 용\n",
    "        self.df = original_df.iloc[np.array(self.input_ids)[:, -1]]\n",
    "        \n",
    "    ## Dataset은 반드시 __len__ 함수를 만들어줘야함(데이터 길이)\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    ## Dataset은 반드시 __getitem__ 함수를 만들어줘야함\n",
    "    ## torch 모듈은 __getitem__ 을 호출하여 학습할 데이터를 불러옴.\n",
    "    def __getitem__(self, item):\n",
    "        temp_input_ids = self.input_ids[item]\n",
    "        input_values = self.var_data[temp_input_ids]\n",
    "        return input_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch의 Dataset을 상속받아 데이터 클래스를 구성합니다. 데이터 클래스는 정규화 과정을 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 인코더\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=4096, hidden_size=1024, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=0.1, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, (hidden, cell) = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "## 디코더\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=4096, hidden_size=1024, output_size=4096, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=0.1, bidirectional=False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, (hidden, cell) = self.lstm(x, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        prediction = self.fc(output)\n",
    "\n",
    "        return prediction, (hidden, cell)\n",
    "    \n",
    "## LSTM Auto Encoder\n",
    "class LSTMAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 window_size: int=1,\n",
    "                 **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        :param input_dim: 변수 Tag 갯수\n",
    "        :param latent_dim: 최종 압축할 차원 크기\n",
    "        :param window_size: 길이\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.window_size = window_size\n",
    "\n",
    "        if \"num_layers\" in kwargs:\n",
    "            num_layers = kwargs.pop(\"num_layers\")\n",
    "        else:\n",
    "            num_layers = 1\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.reconstruct_decoder = Decoder(\n",
    "            input_size=input_dim,\n",
    "            output_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, src:torch.Tensor, **kwargs):\n",
    "        batch_size, sequence_length, var_length = src.size()\n",
    "\n",
    "        ## Encoder 넣기\n",
    "        encoder_hidden = self.encoder(src)\n",
    "        \n",
    "        inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "        reconstruct_output = []\n",
    "        temp_input = torch.zeros((batch_size, 1, var_length), dtype=torch.float).to(src.device)\n",
    "        hidden = encoder_hidden\n",
    "        for t in range(sequence_length):\n",
    "            temp_input, hidden = self.reconstruct_decoder(temp_input, hidden)\n",
    "            reconstruct_output.append(temp_input)\n",
    "        reconstruct_output = torch.cat(reconstruct_output, dim=1)[:, inv_idx, :]\n",
    "        \n",
    "        return [reconstruct_output, src]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        \n",
    "        ## MSE loss(Mean squared Error)\n",
    "        loss =F.mse_loss(recons, input)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args, model, train_loader, test_loader):\n",
    "    # optimizer 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    ## 반복 횟수 Setting\n",
    "    epochs = tqdm(range(args.max_iter//len(train_loader)+1))\n",
    "    \n",
    "    ## 학습하기\n",
    "    count = 0\n",
    "    best_loss = 100000000\n",
    "    for epoch in epochs:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"training\")\n",
    "\n",
    "        for i, batch_data in train_iterator:\n",
    "            \n",
    "            if count > args.max_iter:\n",
    "                return model\n",
    "            count += 1\n",
    "            \n",
    "            batch_data = batch_data.to(args.device)\n",
    "            predict_values = model(batch_data)\n",
    "            loss = model.loss_function(*predict_values)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_iterator.set_postfix({\n",
    "                \"train_loss\": float(loss),\n",
    "            })\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\")\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in test_iterator:\n",
    "                \n",
    "                batch_data = batch_data.to(args.device)\n",
    "                predict_values = model(batch_data)\n",
    "                loss = model.loss_function(*predict_values)\n",
    "\n",
    "                eval_loss += loss.mean().item()\n",
    "\n",
    "                test_iterator.set_postfix({\n",
    "                    \"eval_loss\": float(loss),\n",
    "                })\n",
    "        eval_loss = eval_loss / len(test_loader)\n",
    "        epochs.set_postfix({\n",
    "             \"Evaluation Score\": float(eval_loss),\n",
    "        })\n",
    "        if eval_loss < best_loss:\n",
    "            best_loss = eval_loss\n",
    "        else:\n",
    "            if args.early_stop:\n",
    "                print('early stop condition   best_loss[{}]  eval_loss[{}]'.format(best_loss, eval_loss))\n",
    "                return model\n",
    "        \n",
    "    return model\n",
    "\n",
    "def get_loss_list(args, model, test_loader):\n",
    "    test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\")\n",
    "    loss_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch_data in test_iterator:\n",
    "                \n",
    "            batch_data = batch_data.to(args.device)\n",
    "            predict_values = model(batch_data)\n",
    "            \n",
    "            ## MAE(Mean Absolute Error)로 계산\n",
    "            loss = F.l1_loss(predict_values[0], predict_values[1], reduce=False)\n",
    "            #loss = loss.sum(dim=2).sum(dim=1).cpu().numpy()\n",
    "            loss = loss.mean(dim=1).cpu().numpy()\n",
    "            loss_list.append(loss)\n",
    "    loss_list = np.concatenate(loss_list, axis=0)\n",
    "    return loss_list"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
